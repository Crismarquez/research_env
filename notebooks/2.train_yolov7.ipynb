{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **How to Train YOLOv7 on a Custom Dataset**"
      ],
      "metadata": {
        "id": "wxycE-u1cDzn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fn6B4UHscEF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Setting up Dependencies and paths**"
      ],
      "metadata": {
        "id": "brVuj8S4c11e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kXdxirR5dubf",
        "outputId": "bba735d9-9d51-4790-df4a-2d05a07bea53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.21-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 136 kB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 65.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 961 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 947 kB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=484211e921848582faa5f2e43eb6285a0c6ed9de277f16f5cad933411632d1ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.21 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "nZLivqscc1C6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C9BU493c6rl",
        "outputId": "f53dc90b-0e56-4dfb-fef8-ec8517a4b484"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configure the project directory\n",
        "project_dir = \"project_research\"\n",
        "BASE_DIR = Path(Path.cwd(), \"drive/MyDrive/demolabs\", project_dir)"
      ],
      "metadata": {
        "id": "pX0mKcPNdAfH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_MODEL_NAME = [\n",
        "    \"yolov7.pt\"\n",
        "]\n",
        "# PRETRAINED_MODEL_NAME = [\n",
        "#     \"yolov7.pt\", \"yolov7x.pt\", \"yolov7-w6.pt\", \"yolov7-e6.pt\", \"yolov7-d6.pt\", \"yolov7-e6e.pt\"\n",
        "# ]"
      ],
      "metadata": {
        "id": "vNi7kyhDdHmi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': Path(BASE_DIR, 'workspace'),\n",
        "    'SCRIPTS_PATH': Path(BASE_DIR,'scripts'),\n",
        "    'ANNOTATION_PATH': Path(BASE_DIR, 'workspace','annotations'),\n",
        "    'IMAGE_PATH': Path(BASE_DIR, 'workspace','images'),\n",
        "    'RESULTS_PATH': Path(BASE_DIR, 'workspace','results'),\n",
        "    'DETECTOR_PATH': Path(BASE_DIR, 'workspace','yolov7'),\n",
        "}"
      ],
      "metadata": {
        "id": "rIZPOheidIQ7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix': #linux\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt': # windows\n",
        "            !mkdir {path}"
      ],
      "metadata": {
        "id": "_VOZ7sZWdKzM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Clone repo Yolov7"
      ],
      "metadata": {
        "id": "e54ESuU8dNp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git {paths[\"DETECTOR_PATH\"]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhJMQBGZdSic",
        "outputId": "06ed3aff-da35-474e-858c-d0ca8f878aeb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/demolabs/project_research/workspace/yolov7' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd {paths[\"DETECTOR_PATH\"]}\n",
        "wget https://raw.githubusercontent.com/WongKinYiu/yolov7/u5/requirements.txt\n",
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyL0ccKMdWVc",
        "outputId": "887a6d8f-5f37-4cae-f706-4bbeecc07b05"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (2.28.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (4.64.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 18)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 23)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 36)) (5.4.8)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.38.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.51.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 22)) (2022.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 35)) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 35)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 35)) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 35)) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 35)) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 35)) (5.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 35)) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 35)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 35)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->-r requirements.txt (line 35)) (0.7.0)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 1: cd: {paths[DETECTOR_PATH]}: No such file or directory\n",
            "--2022-12-08 17:27:09--  https://raw.githubusercontent.com/WongKinYiu/yolov7/u5/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1032 (1.0K) [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "     0K .                                                     100% 49.7M=0s\n",
            "\n",
            "2022-12-08 17:27:10 (49.7 MB/s) - ‘requirements.txt’ saved [1032/1032]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paths[\"WEIGHTS_PATH\"] = paths[\"DETECTOR_PATH\"] / \"weights\"\n",
        "\n",
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix': #linux\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt': # windows\n",
        "            !mkdir {path}"
      ],
      "metadata": {
        "id": "xYlZiv3EdYCX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detector directory in system path \n",
        "sys.path.append(str(paths[\"DETECTOR_PATH\"]))"
      ],
      "metadata": {
        "id": "82MVnHNJdchb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Download pre-trained models"
      ],
      "metadata": {
        "id": "njb56640dnDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in PRETRAINED_MODEL_NAME:\n",
        "  !wget -P {paths[\"WEIGHTS_PATH\"]} {\"https://github.com/WongKinYiu/yolov7/releases/download/v0.1/\" + model}"
      ],
      "metadata": {
        "id": "uP4fMY1Ydfje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6aeaaf7-b11b-4340-8cea-725065f9d0e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-08 17:28:03--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221208T172803Z&X-Amz-Expires=300&X-Amz-Signature=636d84720751c4a3bb1669a76e8a0473023ac244820c7b874bcdb5bd520ccf58&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-12-08 17:28:03--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221208%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221208T172803Z&X-Amz-Expires=300&X-Amz-Signature=636d84720751c4a3bb1669a76e8a0473023ac244820c7b874bcdb5bd520ccf58&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75587165 (72M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/MyDrive/demolabs/project_research/workspace/yolov7/weights/yolov7.pt.3’\n",
            "\n",
            "yolov7.pt.3         100%[===================>]  72.08M  13.5MB/s    in 8.1s    \n",
            "\n",
            "2022-12-08 17:28:12 (8.88 MB/s) - ‘/content/drive/MyDrive/demolabs/project_research/workspace/yolov7/weights/yolov7.pt.3’ saved [75587165/75587165]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Getting Our Dataset**\n",
        "\n",
        "If you haven't followed the link to dataset given in description, here it is again [waste segregation](https://universe.roboflow.com/dark-mqa4m/waste-segregation-3ykjs)\n",
        "\n",
        "- Follow the link and sign in to your Roboflow account. If you haven't signed up before, first sign up and then sign in\n",
        "- Once you are login, click the **Download this Dataset** tab in the top right corner\n",
        "- A dialogue box will open, select the YOLOv7 format, check the **Show download code** option and press continue.\n",
        "- A download code will appear "
      ],
      "metadata": {
        "id": "70DB4BlHdzNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {paths[\"DETECTOR_PATH\"]}\n",
        "#### ROBOFLOW DATASET DOWNLOAD CODE #####\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"\")\n",
        "project = rf.workspace(\"dark-mqa4m\").project(\"waste-segregation-3ykjs\")\n",
        "dataset = project.version(3).download(\"yolov7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp-gOTDCdzgi",
        "outputId": "d4fafbfe-9cb5-42ec-e3c1-76e7218f5e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/demolabs/project_research/workspace/yolov7\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in waste-segregation-3 to yolov7pytorch: 100% [291827498 / 291827498] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to waste-segregation-3 in yolov7pytorch::  46%|████▋     | 5399/11646 [49:44<1:08:37,  1.52it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Run YOLOv7 Training**"
      ],
      "metadata": {
        "id": "LdkaJCkgeNsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Getting our pretrained model, you can choose any model from below to fine-tune\n"
      ],
      "metadata": {
        "id": "tEQM6gu6eRHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = PRETRAINED_MODEL_NAME[0]\n",
        "pretrained_model_dir = paths[\"WEIGHTS_PATH\"] / pretrained_model\n"
      ],
      "metadata": {
        "id": "MHDsZQvneN-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Start Training\n",
        "\n",
        "**Note**\n",
        "\n",
        "[To get the full list of training arguments follow the link](https://github.com/WongKinYiu/yolov7/blob/main/train.py)\n",
        "\n",
        "Some important arguments to know\n",
        "- **configuration**: In the main yolov7 folder go to cfg/training folder and select the path of appropriate configuration file. Give the relative path to the file in **--cfg** argument\n",
        "- **data** the path to data folder, it will be automatically catered \n",
        "- **weights** path to pretrained weights given by **--weights** argument\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "**Note for resuming training from checkpoint** <br>\n",
        "By default, the checkpoints for the epoch are stored in folder, yolov7/runs/train, give the relative path to last epoch checkpoints"
      ],
      "metadata": {
        "id": "0_UW7jKbewMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.location"
      ],
      "metadata": {
        "id": "SMl-9luJnRhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {paths[\"DETECTOR_PATH\"]}\n",
        "!python train.py --batch 16 --cfg cfg/training/yolov7.yaml --epochs 10 --data {dataset.location}/data.yaml --weights 'weights/yolov7.pt' --device 0 "
      ],
      "metadata": {
        "id": "f9Te-majewh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKH5A5semXVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Evaluation**\n",
        "\n",
        "- Note the checkpoints from training will be stored by default in runs/train/exp. Take the path of the latest checkpoint\n",
        "\n",
        "We can evaluate the performance of our custom training using the provided evalution script.\n",
        "\n",
        "Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."
      ],
      "metadata": {
        "id": "ZNDW6Dr1mojB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 F1 and Precision Recall Curve"
      ],
      "metadata": {
        "id": "h1JFEukDmtLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "display(Image(paths[\"DETECTOR_PATH\"] / \"runs/train/exp/F1_curve.png\", width=400, height=400))\n",
        "display(Image(paths[\"DETECTOR_PATH\"] / \"runs/train/exp/PR_curve.png\", width=400, height=400))\n",
        "display(Image(paths[\"DETECTOR_PATH\"] / \"runs/train/exp/confusion_matrix.png\", width=500, height=500))"
      ],
      "metadata": {
        "id": "3Dtuafxbmo3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1.1 Run the below cell to evaluate on test images"
      ],
      "metadata": {
        "id": "3M-Et9YyqIT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run evaluation\n",
        "!python detect.py --weights {PATHS[\"WEIGHTS_PATH\"] / \"epoch_054.pt\"} --conf 0.1 --source {paths[\"DETECTOR_PATH\"]/ \"waste-segregation-3/test/images\"}"
      ],
      "metadata": {
        "id": "rVKLa-zYqKLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1.2 Display Inference on Folder of Test Images\n",
        "\n",
        "**Note** From the above output display copy the full path of folder where test images are stored"
      ],
      "metadata": {
        "id": "jQmaY2hbqwXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 100# max images to print\n",
        "for imageName in glob.glob(path[\"DETECTOR_PATH\"] / '/runs/detect/exp1/*.jpg'):\n",
        "    #Assuming JPG\n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1\n",
        "\n",
        "#display(Image(\"/content/gdrive/MyDrive/yolov7/runs/detect/exp3/52_jpg.rf.c3931652d0d6e62034543e92ec110c0b.jpg\", width=400, height=400))"
      ],
      "metadata": {
        "id": "cNIeRumrq0CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.2 Now it's time to Infer on Custom Images**"
      ],
      "metadata": {
        "id": "OJGDovqdrNAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2.1 Helper Code For Inference"
      ],
      "metadata": {
        "id": "ECEwXE72CM5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/yolov7')\n",
        "\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.backends.cudnn as cudnn\n",
        "from numpy import random\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n",
        "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
        "from utils.plots import plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
        "\n",
        "\n",
        "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
        "    # Resize and pad image while meeting stride-multiple constraints\n",
        "    shape = img.shape[:2]  # current shape [height, width]\n",
        "    if isinstance(new_shape, int):\n",
        "        new_shape = (new_shape, new_shape)\n",
        "\n",
        "    # Scale ratio (new / old)\n",
        "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n",
        "        r = min(r, 1.0)\n",
        "\n",
        "    # Compute padding\n",
        "    ratio = r, r  # width, height ratios\n",
        "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
        "    if auto:  # minimum rectangle\n",
        "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
        "    elif scaleFill:  # stretch\n",
        "        dw, dh = 0.0, 0.0\n",
        "        new_unpad = (new_shape[1], new_shape[0])\n",
        "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
        "\n",
        "    dw /= 2  # divide padding into 2 sides\n",
        "    dh /= 2\n",
        "\n",
        "    if shape[::-1] != new_unpad:  # resize\n",
        "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
        "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
        "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
        "    return img, ratio, (dw, dh)"
      ],
      "metadata": {
        "id": "9JXZQC6TrSdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2.2 Configuration Parameters\n",
        "\n",
        "Change the path of both **weights** and **yaml** file\n",
        "\n",
        "**weights** will be in yolov7 main folder -> runs -> train and then select the appropriate weight\n",
        "\n",
        "**yaml** yolov7 main folder -> Trash-5, there you will find yaml file"
      ],
      "metadata": {
        "id": "aWuDwXtRCUqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes_to_filter = None  #You can give list of classes to filter by name, Be happy you don't have to put class number. ['train','person' ]\n",
        "\n",
        "\n",
        "opt  = {\n",
        "    \n",
        "    \"weights\": \"/content/gdrive/MyDrive/yolov7/runs/train/exp/weights/epoch_024.pt\", # Path to weights file default weights are for nano model\n",
        "    \"yaml\"   : \"Trash-5/data.yaml\",\n",
        "    \"img-size\": 640, # default image size\n",
        "    \"conf-thres\": 0.25, # confidence threshold for inference.\n",
        "    \"iou-thres\" : 0.45, # NMS IoU threshold for inference.\n",
        "    \"device\" : '0',  # device to run our model i.e. 0 or 0,1,2,3 or cpu\n",
        "    \"classes\" : classes_to_filter  # list of classes to filter or None\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "pa935dAGCQ_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.3. Inference on Single Image**\n"
      ],
      "metadata": {
        "id": "cVheI4yfCdkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/yolov7\n",
        "!gdown https://drive.google.com/uc?id=1c96hId8WNsOASKHcAxsQeM4N-N2wuwy9\n",
        "#This does not work in Safari Browser"
      ],
      "metadata": {
        "id": "w8WD-p87CllV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_image_path = '/content/gdrive/MyDrive/yolov7/trash.jpg'\n",
        "#Change the Path Name to your file name."
      ],
      "metadata": {
        "id": "SAA3sODiCrkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give path of source image.\n",
        "#%cd /content/gdrive/MyDrive/yolov7\n",
        "#source_image_path = '/content/trash.png'\n",
        "\n",
        "with torch.no_grad():\n",
        "  weights, imgsz = opt['weights'], opt['img-size']\n",
        "  set_logging()\n",
        "  device = select_device(opt['device'])\n",
        "  half = device.type != 'cpu'\n",
        "  model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "  stride = int(model.stride.max())  # model stride\n",
        "  imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
        "  if half:\n",
        "    model.half()\n",
        "\n",
        "  names = model.module.names if hasattr(model, 'module') else model.names\n",
        "  colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
        "  if device.type != 'cpu':\n",
        "    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))\n",
        "\n",
        "  img0 = cv2.imread(source_image_path)\n",
        "  img = letterbox(img0, imgsz, stride=stride)[0]\n",
        "  img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "  img = np.ascontiguousarray(img)\n",
        "  img = torch.from_numpy(img).to(device)\n",
        "  img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "  img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "  if img.ndimension() == 3:\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "  # Inference\n",
        "  t1 = time_synchronized()\n",
        "  pred = model(img, augment= False)[0]\n",
        "\n",
        "  # Apply NMS\n",
        "  classes = None\n",
        "  if opt['classes']:\n",
        "    classes = []\n",
        "    for class_name in opt['classes']:\n",
        "\n",
        "      classes.append(opt['classes'].index(class_name))\n",
        "\n",
        "\n",
        "  pred = non_max_suppression(pred, opt['conf-thres'], opt['iou-thres'], classes= classes, agnostic= False)\n",
        "  t2 = time_synchronized()\n",
        "  for i, det in enumerate(pred):\n",
        "    s = ''\n",
        "    s += '%gx%g ' % img.shape[2:]  # print string\n",
        "    gn = torch.tensor(img0.shape)[[1, 0, 1, 0]]\n",
        "    if len(det):\n",
        "      det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n",
        "\n",
        "      for c in det[:, -1].unique():\n",
        "        n = (det[:, -1] == c).sum()  # detections per class\n",
        "        s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "    \n",
        "      for *xyxy, conf, cls in reversed(det):\n",
        "\n",
        "        label = f'{names[int(cls)]} {conf:.2f}'\n",
        "        plot_one_box(xyxy, img0, label=label, color=colors[int(cls)], line_thickness=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "NVmSVhJUCzrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img0)"
      ],
      "metadata": {
        "id": "iHc8kciDC2VH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}